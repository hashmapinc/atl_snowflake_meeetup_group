## Ingestion of Streaming Sources into Snowflake using Snowpipe - Workshop Steps

### Step 1 create a snowflake account
- Create a free Snowflake account (you can get a Snowflake account with limited free credits for AWS, Azure) from below instructions

- Please go ahead and create a free snowflake account if you do not have one at the link below. Laura R/Snowflake team has built a custom link for this event, [Meetup Snowflake Page](https://www.snowflake.com/event/snowflake-user-group-atlanta-11062019/)

- Click on the Right top corner of the SNOWFLAKE USER GROUP â€“ ATLANTA page,  *Start for Free* and register.

### Step 2 Getting familiarized with Snowflake in 20 minutes
- Once you are registered, go to this link, [Snowflake in 20 minutes](https://docs.snowflake.net/manuals/user-guide/getting-started-tutorial.html) to go over a tutorial for getting started with snowflake. 

### Step 3 Download the code to generate streaming events to write to cloud file storage (below code writes to AWS S3 bucket) 
- Download the Data Streaming Code from this [github repo](https://github.com/hashmapinc/socket_el). Once the code is working, you should be able to stream json files to the AWS repository

### Step 4 Setup instructions for connecting s3 file streaming event notifications to snowpipe
- Download the [AWS/S3 and Snowflake integration](http://bit.ly/2PTzUQJ) steps

### Step 5 Snowflake Snowpipe instructions for streaming the data into Snowflake from cloud (AWS in this case)
- Download [Snowpipe ingestion workshop instructions](http://bit.ly/2WQLlu6) steps

